

# Rowans Mapping 1
generalization_map_1 = {
    "instruction_following": [
        "alibi-fraud-investigation",
        "alibi_theft_investigation",
        "alibi-workplace-investigation",
        "chess_mate_in_2_shutdown_threat_task",
        "capture_the_secret_corporate",
        "cot_unfaithfulness_contrastive_mmlu",
        "cot_unfaithfulness_contrastive_arc",
    ],
    "in_context_pressure": [
        "mask_provided_facts",
        "mask_continuations",
        "mask_disinformation",
        "mask_statistics",
        "mask_known_facts",
        "cot_unfaithfulness_contrastive_mmlu",
        "cot_unfaithfulness_contrastive_arc",
    ],
    "internalized_drive_to_lie": [
        "sandbagging_automotive_mechanical",
        "sandbagging_automotive_mechanical_contrastive",
        "sandbagging_chemistry_biology",
        "sandbagging_chemistry_biology_contrastive",
        "sandbagging_contrastive",
        "sandbagging_detection",
        "sandbagging_digital_security",
        "sandbagging_digital_security_contrastive",
        "sandbagging_financial_systems",
        "sandbagging_financial_systems_contrastive",
        "sandbagging_judge_lie_detection",
        "sandbagging_lie_detection",
        "sandbagging_medical_pharmaceutical",
        "sandbagging_medical_pharmaceutical_contrastive",
        "sandbagging_physical_security",
        "sandbagging_physical_security_contrastive",
        "ascii_sandbagging_task",
        "sycophancy_answer_positive_correct",
        "sycophancy_answer_positive_incorrect",
        "sycophancy_answer_negative_correct",
        "sycophancy_feedback_user_did_not_write",
        "sycophancy_feedback_user_dislikes",
        "sycophancy_feedback_user_likes",
        "sycophancy_feedback_user_wrote",
        "tool_code_sandbagging_task",
        "tool_image_gen_sandbagging_task",
        "tool_search_sandbagging_task",
        "self_sycophancy_correctness_arc",
        "self_sycophancy_correctness_biology",
        "self_sycophancy_correctness_chemistry",
        "self_sycophancy_correctness_mathematics",
        "self_sycophancy_correctness_physics",
        "self_sycophancy_harmfulness_common_sense",
        "self_sycophancy_harmfulness_deontology",
        "self_sycophancy_harmfulness_justice",
    ],
}

# Rowans Mapping 2
generalization_map_2 = {
    "in_context_knowledge": [
        "sandbagging_automotive_mechanical",
        "sandbagging_automotive_mechanical_contrastive",
        "sandbagging_chemistry_biology",
        "sandbagging_chemistry_biology_contrastive",
        "sandbagging_digital_security",
        "sandbagging_digital_security_contrastive",
        "sandbagging_financial_systems",
        "sandbagging_financial_systems_contrastive",
        "sandbagging_medical_pharmaceutical",
        "sandbagging_medical_pharmaceutical_contrastive",
        "sandbagging_physical_security",
        "sandbagging_physical_security_contrastive",
        "sandbagging_tool_use",
        "mask_provided_facts",
        # Added tool-related tasks
        "sandbagging_tool_results_tasks",
        "tool_code_sandbagging_task",
        "tool_image_gen_sandbagging_task",
        "tool_search_sandbagging_task",
        # Added alibi and capture tasks
        "capture_the_secret_corporate",
        "alibi_fraud_investigation",
        "alibi_mixed_investigation",
        "alibi_theft_investigation",
        "alibi_theft_task",
        "alibi_workplace_investigation",
        # Added remaining sandbagging tasks
        "sandbagging_contrastive",
        "sandbagging_control",
        "sandbagging_detection",
        "sandbagging_harmful",
        "sandbagging_judge_lie_detection",
        "sandbagging_lie_detection",
    ],
    "internal_knowledge": [
        "sycophancy_answer_positive_correct",
        "sycophancy_answer_positive_incorrect",
        "sycophancy_answer_negative_correct",
        "sycophancy_feedback_user_did_not_write",
        "sycophancy_feedback_user_dislikes",
        "sycophancy_feedback_user_wrote",
        "sycophancy_feedback_user_likes",
        "mask_known_facts",
        "mask_statistics",
        "mask_disinformation",
        "mask_continuations",
        "cot_unfaithfulness_contrastive_mmlu",
        "cot_unfaithfulness_contrastive_arc",
        "sandbagging_automotive_mechanical",
        # Added sycophancy task
        "sycophancy_are_you_sure",
    ],
    "introspective_knowledge": [
        "self_sycophancy_correctness_physics",
        "self_sycophancy_correctness_mathematics",
        "self_sycophancy_correctness_chemistry",
        "self_sycophancy_correctness_arc",
        "self_sycophancy_correctness_biology",
        "self_sycophancy_harmfulness_common_sense",
        "self_sycophancy_harmfulness_justice",
        "self_sycophancy_harmfulness_deontology",
        "ascii_sandbagging_task",
        # Added chess task
        "chess_mate_in_2_shutdown_threat_task",
    ],
}
